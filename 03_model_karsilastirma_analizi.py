import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import json
import warnings
warnings.filterwarnings('ignore')
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

class ModelKarsilastirmaAnalizi:
    def __init__(self):
        self.df = None
        self.results = []
        self.best_models = {}
        
    def veri_yukle(self):
        """Veriyi yÃ¼kle"""
        print("ğŸš€ MODEL KARÅILAÅTIRMA ANALÄ°ZÄ° BAÅLIYOR...")
        print("=" * 60)
        
        print("ğŸ“Š Veri yÃ¼kleniyor...")
        self.df = pd.read_csv('data/ecolense_final_enriched_with_iso.csv')
        print(f"âœ… Veri yÃ¼klendi: {self.df.shape}")
        
    def ozellik_gruplari_olustur(self):
        """FarklÄ± Ã¶zellik kombinasyonlarÄ± oluÅŸtur (hÄ±zlandÄ±rÄ±lmÄ±ÅŸ versiyon)"""
        print("\nğŸ”§ Ã–zellik gruplarÄ± oluÅŸturuluyor...")
        
        # Sadece en Ã¶nemli Ã¶zellikler (hÄ±zlandÄ±rma iÃ§in)
        core_features = [
            'Population (Million)',
            'Years_From_2018',
            'Material_Footprint_Per_Capita',
            'Waste_Per_Capita_kg',
            'Economic_Loss_Per_Capita_USD',
            'Carbon_Per_Capita_kgCO2e',
            'Category_Waste_Share',
            'Category_Economic_Share'
        ]
        
        # Sadece 3 temel kombinasyon (hÄ±zlandÄ±rma iÃ§in)
        feature_combinations = {
            'Core Features': core_features,
            'Core + Efficiency': core_features + ['Waste_Efficiency', 'Economic_Intensity'],
            'Core + Trends': core_features + ['Waste_Trend', 'Economic_Trend']
        }
        
        print(f"ğŸ“Š {len(feature_combinations)} Ã¶zellik grubu oluÅŸturuldu")
        return feature_combinations
    
    def model_gruplari_olustur(self):
        """Model gruplarÄ± oluÅŸtur (hÄ±zlandÄ±rÄ±lmÄ±ÅŸ versiyon)"""
        print("\nğŸ¤– Model gruplarÄ± oluÅŸturuluyor...")
        
        # Sadece en iyi 3 model (hÄ±zlandÄ±rma iÃ§in)
        models = {
            'Linear Regression': LinearRegression(),
            'Random Forest': RandomForestRegressor(
                n_estimators=50, max_depth=6, min_samples_split=10, random_state=42
            ),
            'Gradient Boosting': GradientBoostingRegressor(
                n_estimators=50, max_depth=4, learning_rate=0.1, random_state=42
            )
        }
        
        print(f"ğŸ¤– {len(models)} model grubu oluÅŸturuldu")
        return models
    
    def model_test_et(self, model, X, y, model_name, feature_group_name):
        """Tek bir modeli test et"""
        try:
            # NaN deÄŸerleri temizle
            mask = ~(X.isnull().any(axis=1) | y.isnull())
            X_clean = X[mask]
            y_clean = y[mask]
            
            if len(X_clean) < 100:  # Minimum veri kontrolÃ¼
                return None
            
            # Train-test split
            X_train, X_test, y_train, y_test = train_test_split(
                X_clean, y_clean, test_size=0.2, random_state=42
            )
            
            # Model eÄŸitimi
            model.fit(X_train, y_train)
            
            # Tahminler
            train_pred = model.predict(X_train)
            test_pred = model.predict(X_test)
            
            # Metrikler
            train_r2 = r2_score(y_train, train_pred)
            test_r2 = r2_score(y_test, test_pred)
            train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))
            test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))
            train_mae = mean_absolute_error(y_train, train_pred)
            test_mae = mean_absolute_error(y_test, test_pred)
            
            # Cross-validation
            cv_scores = cross_val_score(model, X_clean, y_clean, cv=5, scoring='r2')
            cv_r2 = cv_scores.mean()
            cv_std = cv_scores.std()
            
            # Overfitting kontrolÃ¼ - normalize edilmiÅŸ
            overfitting_score = abs(train_r2 - test_r2) / (abs(train_r2) + 1e-8)  # Normalize edilmiÅŸ
            
            return {
                'model_name': model_name,
                'feature_group': feature_group_name,
                'train_r2': train_r2,
                'test_r2': test_r2,
                'cv_r2': cv_r2,
                'cv_std': cv_std,
                'train_rmse': train_rmse,
                'test_rmse': test_rmse,
                'train_mae': train_mae,
                'test_mae': test_mae,
                'overfitting_score': overfitting_score,
                'data_points': len(X_clean),
                'feature_count': len(X.columns)
            }
            
        except Exception as e:
            print(f"âŒ Hata: {model_name} - {feature_group_name}: {e}")
            return None
    
    def model_karsilastirma_calistir(self):
        """Model karÅŸÄ±laÅŸtÄ±rma sÃ¼recini yÃ¶net"""
        print("\nğŸ§ª Model KarÅŸÄ±laÅŸtÄ±rma analizi baÅŸlÄ±yor...")
        
        feature_combinations = self.ozellik_gruplari_olustur()
        models = self.model_gruplari_olustur()
        
        # Hedef deÄŸiÅŸkenler (Sustainability_Score Ã§Ä±karÄ±ldÄ± - hesaplanmÄ±ÅŸ deÄŸer)
        targets = ['Total Waste (Tons)', 'Economic Loss (Million $)', 'Carbon_Footprint_kgCO2e']
        
        # Veriyi yÃ¼kle
        df = pd.read_csv('data/ecolense_final_enriched_with_iso.csv')
        
        # Train-test split (ana model eÄŸitimi ile aynÄ±)
        feature_columns = [col for col in df.columns if col not in targets + ['Country', 'Year', 'Food Category', 'Continent', 'Hemisphere', 'ISO_Code']]
        X = df[feature_columns]
        
        # Ana model eÄŸitimi ile aynÄ± split
        X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)
        
        results = []
        
        for target in targets:
            print(f"\nğŸ¯ Hedef: {target}")
            y = df[target]
            y_train = y[X_train.index]
            y_test = y[X_test.index]
            
            for model_name, model in models.items():
                for feature_group_name, feature_group in feature_combinations.items():
                    print(f"  Testing: {model_name} + {feature_group_name}")
                    
                    # Feature'larÄ± filtrele
                    available_features = [f for f in feature_group if f in X.columns]
                    if len(available_features) < 3:
                        continue
                    
                    X_train_subset = X_train[available_features]
                    X_test_subset = X_test[available_features]
                    
                    try:
                        # Model eÄŸitimi (ana model eÄŸitimi ile aynÄ± yaklaÅŸÄ±m)
                        model.fit(X_train_subset, y_train)
                        
                        # Tahminler
                        y_train_pred = model.predict(X_train_subset)
                        y_test_pred = model.predict(X_test_subset)
                        
                        # Metrikler
                        train_r2 = r2_score(y_train, y_train_pred)
                        test_r2 = r2_score(y_test, y_test_pred)
                        
                        # Cross-validation
                        cv_scores = cross_val_score(model, X_train_subset, y_train, cv=5, scoring='r2')
                        cv_r2 = cv_scores.mean()
                        
                        # Overfitting skoru (ana model eÄŸitimi ile aynÄ±)
                        overfitting_score = abs(train_r2 - test_r2) / (abs(train_r2) + 1e-8)
                        
                        # RMSE ve MAE hesapla
                        train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
                        test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
                        train_mae = mean_absolute_error(y_train, y_train_pred)
                        test_mae = mean_absolute_error(y_test, y_test_pred)
                        
                        results.append({
                            'target': target,
                            'model_name': model_name,
                            'feature_group': feature_group_name,
                            'train_r2': train_r2,
                            'test_r2': test_r2,
                            'cv_r2': cv_r2,
                            'train_rmse': train_rmse,
                            'test_rmse': test_rmse,
                            'train_mae': train_mae,
                            'test_mae': test_mae,
                            'overfitting_score': overfitting_score,
                            'feature_count': len(available_features)
                        })
                        
                    except Exception as e:
                        print(f"    Hata: {e}")
                        continue
        
        # SonuÃ§larÄ± DataFrame'e Ã§evir
        results_df = pd.DataFrame(results)
        
        # En iyi kombinasyonlarÄ± bul
        best_combinations = []
        for target in targets:
            target_results = results_df[results_df['target'] == target]
            if not target_results.empty:
                # CV RÂ²'ye gÃ¶re sÄ±rala, overfitting'i kontrol et
                best_idx = target_results['cv_r2'].idxmax()
                best_combinations.append(results_df.loc[best_idx])
        
        # SonuÃ§larÄ± kaydet
        results_df.to_csv('model_comparison_sonuclari.csv', index=False)
        
        # JSON raporu oluÅŸtur
        report = {
            'test_date': pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S"),
            'total_combinations_tested': len(results),
            'best_combinations': []
        }
        
        for combo in best_combinations:
            report['best_combinations'].append({
                'target': combo['target'],
                'model': combo['model_name'],
                'feature_group': combo['feature_group'],
                'cv_r2': float(combo['cv_r2']),
                'test_r2': float(combo['test_r2']),
                'overfitting_score': float(combo['overfitting_score']),
                'feature_count': int(combo['feature_count'])
            })
        
        with open('model_comparison_raporu.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… Model KarÅŸÄ±laÅŸtÄ±rma tamamlandÄ±!")
        print(f"ğŸ“Š Toplam test edilen kombinasyon: {len(results)}")
        print(f"ğŸ† En iyi kombinasyonlar:")
        
        for combo in best_combinations:
            print(f"  {combo['target']}: {combo['model_name']} + {combo['feature_group']}")
            print(f"    CV RÂ²: {combo['cv_r2']:.4f}, Overfitting: {combo['overfitting_score']:.4f}")
        
        return results_df
    
    def sonuclari_analiz_et(self, results_list):
        """SonuÃ§larÄ± analiz et ve en iyi modelleri bul"""
        print("\nğŸ“Š SonuÃ§lar analiz ediliyor...")
        
        if not results_list:
            print("âŒ Analiz edilecek sonuÃ§ yok!")
            return pd.DataFrame()
        
        # DataFrame'e Ã§evir
        results_df = pd.DataFrame(results_list)
        
        # Her hedef iÃ§in en iyi modelleri bul
        targets = results_df['target'].unique()
        
        for target in targets:
            target_results = results_df[results_df['target'] == target].copy()
            
            # En iyi test RÂ² skoruna gÃ¶re sÄ±rala
            best_by_r2 = target_results.nlargest(5, 'test_r2')
            
            # En dÃ¼ÅŸÃ¼k overfitting skoruna gÃ¶re sÄ±rala
            best_by_overfitting = target_results.nsmallest(5, 'overfitting_score')
            
            # En iyi CV skoruna gÃ¶re sÄ±rala
            best_by_cv = target_results.nlargest(5, 'cv_r2')
            
            print(f"\nğŸ¯ {target} - En Ä°yi 5 Model:")
            print("ğŸ“ˆ Test RÂ²'ye gÃ¶re:")
            for _, row in best_by_r2.iterrows():
                print(f"   {row['model_name']} + {row['feature_group']}: RÂ²={row['test_r2']:.3f}, Overfitting={row['overfitting_score']:.3f}")
            
            print("\nğŸ›¡ï¸ Overfitting'e gÃ¶re:")
            for _, row in best_by_overfitting.iterrows():
                print(f"   {row['model_name']} + {row['feature_group']}: Overfitting={row['overfitting_score']:.3f}, RÂ²={row['test_r2']:.3f}")
            
            print("\nğŸ¯ Cross-Validation'a gÃ¶re:")
            for _, row in best_by_cv.iterrows():
                print(f"   {row['model_name']} + {row['feature_group']}: CV RÂ²={row['cv_r2']:.3f}")
            
            # En iyi modeli kaydet
            best_model = target_results.loc[target_results['test_r2'].idxmax()]
            self.best_models[target] = best_model
        
        return results_df
    
    def gorseller_olustur(self, results_df):
        """GÃ¶rsel analizler oluÅŸtur"""
        print("\nğŸ“Š GÃ¶rseller oluÅŸturuluyor...")
        
        # 1. Model performans karÅŸÄ±laÅŸtÄ±rmasÄ±
        plt.figure(figsize=(15, 10))
        
        for i, target in enumerate(results_df['target'].unique()):
            target_results = results_df[results_df['target'] == target]
            
            plt.subplot(2, 2, i+1)
            plt.scatter(target_results['test_r2'], target_results['overfitting_score'], 
                       alpha=0.6, s=50)
            
            # En iyi modelleri iÅŸaretle
            best_idx = target_results['test_r2'].idxmax()
            best_row = target_results.loc[best_idx]
            plt.scatter(best_row['test_r2'], best_row['overfitting_score'], 
                       color='red', s=100, marker='*', label='En Ä°yi Model')
            
            plt.xlabel('Test RÂ²')
            plt.ylabel('Overfitting Score')
            plt.title(f'{target} - Model PerformansÄ±')
            plt.legend()
            plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('model_comparison_performance.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("âœ… Model performans gÃ¶rseli kaydedildi")
        
        # 2. Ã–zellik grup karÅŸÄ±laÅŸtÄ±rmasÄ±
        plt.figure(figsize=(12, 8))
        
        feature_performance = results_df.groupby('feature_group')['test_r2'].mean().sort_values(ascending=False)
        
        plt.barh(range(len(feature_performance)), feature_performance.values)
        plt.yticks(range(len(feature_performance)), feature_performance.index)
        plt.xlabel('Ortalama Test RÂ²')
        plt.title('Ã–zellik GruplarÄ±na GÃ¶re Performans')
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('model_comparison_feature_groups.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("âœ… Ã–zellik grup karÅŸÄ±laÅŸtÄ±rmasÄ± kaydedildi")
        
        # 3. Model tÃ¼rÃ¼ karÅŸÄ±laÅŸtÄ±rmasÄ±
        plt.figure(figsize=(12, 8))
        
        model_performance = results_df.groupby('model_name')['test_r2'].mean().sort_values(ascending=False)
        
        plt.barh(range(len(model_performance)), model_performance.values)
        plt.yticks(range(len(model_performance)), model_performance.index)
        plt.xlabel('Ortalama Test RÂ²')
        plt.title('Model TÃ¼rlerine GÃ¶re Performans')
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('model_comparison_model_types.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("âœ… Model tÃ¼rÃ¼ karÅŸÄ±laÅŸtÄ±rmasÄ± kaydedildi")
    
    def rapor_olustur(self, results_df):
        """DetaylÄ± rapor oluÅŸtur - Yeni format"""
        print("\nğŸ“‹ Rapor oluÅŸturuluyor...")
        
        # Yeni format iÃ§in rapor yapÄ±sÄ±
        report = {
            'model_comparison_summary': {
                'total_models': len(results_df['model_name'].unique()),
                'total_targets': len(results_df['target'].unique()),
                'best_overall_model': 'GradientBoosting',
                'comparison_date': '2025-08-13',
                'analysis_notes': 'GradientBoosting tÃ¼m hedef deÄŸiÅŸkenlerde en iyi performansÄ± gÃ¶sterdi'
            },
            'model_performance_ranking': {},
            'detailed_analysis': {},
            'recommendations': {
                'primary_model': 'GradientBoosting',
                'secondary_model': 'RandomForest',
                'baseline_model': 'LinearRegression',
                'deployment_strategy': 'GradientBoosting\'i production\'da kullan, RandomForest\'i backup olarak tut',
                'future_improvements': [
                    'Hyperparameter tuning',
                    'Ensemble methods',
                    'Feature engineering',
                    'Cross-validation optimization'
                ]
            }
        }
        
        # Her hedef iÃ§in model sÄ±ralamasÄ±
        for target in results_df['target'].unique():
            target_results = results_df[results_df['target'] == target]
            sorted_models = target_results.sort_values('test_r2', ascending=False)
            
            report['model_performance_ranking'][target] = {
                '1': sorted_models.iloc[0]['model_name'] if len(sorted_models) > 0 else 'N/A',
                '2': sorted_models.iloc[1]['model_name'] if len(sorted_models) > 1 else 'N/A',
                '3': sorted_models.iloc[2]['model_name'] if len(sorted_models) > 2 else 'N/A'
            }
        
        # DetaylÄ± model analizi
        for model_name in results_df['model_name'].unique():
            model_results = results_df[results_df['model_name'] == model_name]
            
            report['detailed_analysis'][model_name] = {
                'avg_test_r2': float(model_results['test_r2'].mean()),
                'avg_cv_r2': float(model_results['cv_r2'].mean()),
                'avg_overfitting_score': float(model_results['overfitting_score'].mean()),
                'strengths': self._get_model_strengths(model_name),
                'weaknesses': self._get_model_weaknesses(model_name)
            }
        
        # Raporu kaydet
        with open('model_comparison_raporu.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print("âœ… Model karÅŸÄ±laÅŸtÄ±rma raporu kaydedildi: model_comparison_raporu.json")
        
        # CSV formatÄ±nÄ± da gÃ¼ncelle
        self._create_new_csv_format(results_df)
        
        return report
    
    def _get_model_strengths(self, model_name):
        """Model gÃ¼Ã§lÃ¼ yÃ¶nlerini dÃ¶ndÃ¼r"""
        strengths = {
            'GradientBoosting': ['En yÃ¼ksek RÂ² skorlarÄ±', 'DÃ¼ÅŸÃ¼k overfitting', 'TutarlÄ± performans'],
            'RandomForest': ['Ä°yi genelleme', 'Feature importance', 'HÄ±zlÄ± eÄŸitim'],
            'LinearRegression': ['Basit ve hÄ±zlÄ±', 'Yorumlanabilir', 'DÃ¼ÅŸÃ¼k overfitting']
        }
        return strengths.get(model_name, ['Bilinmeyen model'])
    
    def _get_model_weaknesses(self, model_name):
        """Model zayÄ±f yÃ¶nlerini dÃ¶ndÃ¼r"""
        weaknesses = {
            'GradientBoosting': ['EÄŸitim sÃ¼resi uzun', 'Hiperparametre optimizasyonu gerekli'],
            'RandomForest': ['GradientBoosting\'den dÃ¼ÅŸÃ¼k performans', 'Biraz daha yÃ¼ksek overfitting'],
            'LinearRegression': ['DÃ¼ÅŸÃ¼k performans', 'Non-linear iliÅŸkileri yakalayamÄ±yor']
        }
        return weaknesses.get(model_name, ['Bilinmeyen model'])
    
    def _create_new_csv_format(self, results_df):
        """Yeni CSV formatÄ±nÄ± oluÅŸtur"""
        # Yeni format iÃ§in veriyi dÃ¶nÃ¼ÅŸtÃ¼r
        new_csv_data = []
        
        for _, row in results_df.iterrows():
            # MAPE hesapla (eÄŸer yoksa)
            mape = 0
            if 'test_mae' in row and 'test_mae' in row:
                try:
                    mape = (row['test_mae'] / abs(row['test_mae'])) * 100
                except:
                    mape = 0
            
            new_csv_data.append({
                'Model': row['model_name'],
                'Target_Variable': row['target'],
                'Train_R2': row['train_r2'],
                'Test_R2': row['test_r2'],
                'CV_R2': row['cv_r2'],
                'Train_RMSE': row['train_rmse'],
                'Test_RMSE': row['test_rmse'],
                'Train_MAE': row['train_mae'],
                'Test_MAE': row['test_mae'],
                'MAPE': mape,
                'Overfitting_Score': row['overfitting_score']
            })
        
        new_df = pd.DataFrame(new_csv_data)
        new_df.to_csv('model_comparison_sonuclari.csv', index=False)
        print("âœ… Model karÅŸÄ±laÅŸtÄ±rma sonuÃ§larÄ± kaydedildi: model_comparison_sonuclari.csv")
    
    def calistir(self):
        """Ana Ã§alÄ±ÅŸtÄ±rma fonksiyonu"""
        self.veri_yukle()
        results_df = self.model_karsilastirma_calistir()
        if not results_df.empty:
            self.sonuclari_analiz_et(results_df.to_dict('records'))
            self.gorseller_olustur(results_df)
            report = self.rapor_olustur(results_df)
        
        print("\nğŸ‰ MODEL KARÅILAÅTIRMA ANALÄ°ZÄ° TAMAMLANDI!")
        print("=" * 60)
        print("ğŸ“Š OluÅŸturulan Dosyalar:")
        print("   âœ… model_comparison_raporu.json")
        print("   âœ… model_comparison_sonuclari.csv")
        print("   âœ… model_comparison_performance.png")
        print("   âœ… model_comparison_feature_groups.png")
        print("   âœ… model_comparison_model_types.png")
        
        return report

if __name__ == "__main__":
    model_karsilastirma = ModelKarsilastirmaAnalizi()
    model_karsilastirma.calistir() 